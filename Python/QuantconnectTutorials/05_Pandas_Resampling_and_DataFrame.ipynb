{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "05 Pandas-Resampling and DataFrame.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtjOpw6oJp6z"
      },
      "source": [
        "<div align=\"center\">\n",
        "<img style=\"display: block; margin: auto;\" alt=\"photo\" src=\"https://cdn.quantconnect.com/web/i/icon.png\">\n",
        "\n",
        "Quantconnect\n",
        "\n",
        "Introduction to Financial Python\n",
        "</div>\n",
        "\n",
        "# 05 Pandas-Resampling and DataFrame\n",
        "\n",
        "# Introduction\n",
        "In the last chapter we had a glimpse of Pandas. In this chapter we will learn about resampling methods and the DataFrame object, which is a powerful tool for financial data analysis.\n",
        "\n",
        "# Fetching Data\n",
        "Here we use the QuantBook API to retrieve data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luU8mZTsHW9x"
      },
      "source": [
        "# QuantBook Analysis Tool \n",
        "# For more information see [https://www.quantconnect.com/docs/research/overview]\n",
        "qb = QuantBook()\n",
        "aapl = qb.AddEquity(\"AAPL\")\n",
        "start_time = datetime(2016, 1, 1) # start datetime for history call\n",
        "end_time = datetime(2017, 12, 31) # end datetime for history call\n",
        "# Returns daily historical data between January 1st 2016 and December 31st 2017\n",
        "aapl_history = qb.History(aapl.Symbol, start_time, end_time, Resolution.Daily)\n",
        "print(aapl_history.index)\n",
        "print(aapl_history.columns)\n",
        "aapl_history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkFztSYhJyVA"
      },
      "source": [
        "We will create a Series named \"aapl\" whose values are Apple's daily closing prices, which are of course indexed by dates:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1pKPE8YHW90"
      },
      "source": [
        "#Drop de 'AAPL R735QTJ8XC9X' from the Multindex\n",
        "aapl_table = aapl_history.loc['AAPL R735QTJ8XC9X',:]\n",
        "aapl_table"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDJbOpCeHW91"
      },
      "source": [
        "aapl = aapl_table['Adj. Close']['2017']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXfgCQJOHW91"
      },
      "source": [
        "print(aapl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waUEgBhzKEcA"
      },
      "source": [
        "Recall that we can fetch a specific data point using series['yyyy-mm-dd']. We can also fetch the data in a specific month using series['yyyy-mm']."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gS50G0zHW92"
      },
      "source": [
        "print(aapl['2017-3'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpvxGwXtHW92"
      },
      "source": [
        "aapl['2017-2':'2017-4']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWwoD39pKNKb"
      },
      "source": [
        ".head(N) and .tail(N) are methods for quickly accessing the first or last N elements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1eU218ALHW93"
      },
      "source": [
        "print(aapl.head(5))\n",
        "print(aapl.tail(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxhKxtj-KQ66"
      },
      "source": [
        "# Resampling\n",
        "**_series.resample(freq)_** is a class called \"DatetimeIndexResampler\" which groups data in a Series object into regular time intervals. The argument \"freq\" determines the length of each interval.\n",
        "\n",
        "**_series.resample.mean()_** is a complete statement that groups data into intervals, and then compute the mean of each interval. For example, if we want to aggregate the daily data into monthly data by mean:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAV8NkHkHW93"
      },
      "source": [
        "by_month = aapl.resample('M').mean()\n",
        "print(by_month)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDPfVzBEKV6Q"
      },
      "source": [
        "We can also aggregate the data by week:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAP3tKkBHW94"
      },
      "source": [
        "by_week = aapl.resample('W').mean()\n",
        "print(by_week.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_MXSVsILoBS"
      },
      "source": [
        "We can also aggregate the data by month with max:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn0wqXBTHW95"
      },
      "source": [
        "aapl.resample('M').max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8r46UFlLdAh"
      },
      "source": [
        "We can choose almost any frequency by using the format 'nf', where 'n' is an integer and 'f' is M for month, W for week and D for day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdVB_-JFHW96"
      },
      "source": [
        "three_day = aapl.resample('3D').mean()\n",
        "two_week = aapl.resample('2W').mean()\n",
        "two_month = aapl.resample('2M').mean()\n",
        "\n",
        "\n",
        "print(three_day)\n",
        "print(two_week)\n",
        "print(two_month )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy4RqsnwL-Bw"
      },
      "source": [
        "Besides the mean() method, other methods can also be used with the resampler:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNT8Fx9dHW96"
      },
      "source": [
        "std = aapl.resample('W').std()\n",
        "max = aapl.resample('W').max()\n",
        "min = aapl.resample('W').min()\n",
        "\n",
        "\n",
        "print(std)\n",
        "print(max)\n",
        "print(min)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqln0s5DMI3I"
      },
      "source": [
        "Often we want to calculate monthly returns of a stock, based on prices on the last day of each month. To fetch those prices, we use the series.resample.agg() method:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6FSYvqbHW97"
      },
      "source": [
        "last_day = aapl.resample('M').agg(lambda x: x[-1])\n",
        "print(last_day)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwomY3aXMR46"
      },
      "source": [
        "Or directly calculate the monthly rates of return using the data for the first day and the last day:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK2NMJrNHW96"
      },
      "source": [
        "monthly_return = aapl.resample('M').agg(lambda x: x[-1]/x[0] - 1)\n",
        "print(monthly_return)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DYbMTFWMj8J"
      },
      "source": [
        "Series object also provides us some convenient methods to do some quick calculation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mxc0HwvHW98"
      },
      "source": [
        "print(monthly_return.mean())\n",
        "print(monthly_return.std())\n",
        "print(monthly_return.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn59J5dqMpqX"
      },
      "source": [
        "Another two methods frequently used on Series are .diff() and .pct_change(). The former calculates the difference between consecutive elements, and the latter calculates the percentage change."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupZTSqqHW99"
      },
      "source": [
        "print(last_day.diff())\n",
        "print(last_day.pct_change())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaMAOFepM6Io"
      },
      "source": [
        "Notice that we induced a NaN value while calculating percentage changes i.e. returns.\n",
        "\n",
        "When dealing with NaN values, we usually either removing the data point or fill it with a specific value. Here we fill it with 0:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xyLb3A3HW99"
      },
      "source": [
        "daily_return = last_day.pct_change()\n",
        "print(daily_return.fillna(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYS10Om1NQVC"
      },
      "source": [
        "Alternatively, we can fill a NaN with the next fitted value. This is called 'backward fill', or 'bfill' in short:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J513kHeKHW9-"
      },
      "source": [
        "daily_return = last_day.pct_change()\n",
        "print(daily_return.fillna(method = 'bfill'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj8QUSgdNepf"
      },
      "source": [
        "As expected, since there is a 'backward fill' method, there must be a 'forward fill' method, or 'ffill' in short. However we can't use it here because the NaN is the first value.\n",
        "\n",
        "We can also simply remove NaN values by **_.dropna()_**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WG5ux1lqHW9-"
      },
      "source": [
        "daily_return = last_day.pct_change()\n",
        "daily_return.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQH2eBWkNjdC"
      },
      "source": [
        "# DataFrame\n",
        "The **DataFrame** is the most commonly used data structure in Pandas. It is essentially a table, just like an Excel spreadsheet.\n",
        "\n",
        "More precisely, a DataFrame is a collection of Series objects, each of which may contain different data types. A DataFrame can be created from various data types: dictionary, 2-D numpy.ndarray, a Series or another DataFrame.\n",
        "\n",
        "## Create DataFrames\n",
        "The most common method of creating a DataFrame is passing a dictionary:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd5Wf1ohHW9-"
      },
      "source": [
        "dict = {'AAPL': [143.5, 144.09, 142.73, 144.18, 143.77],'GOOG':[898.7, 911.71, 906.69, 918.59, 926.99],\n",
        "        'IBM':[155.58, 153.67, 152.36, 152.94, 153.49]}\n",
        "data_index = pd.date_range('2017-07-03',periods = 5, freq = 'D')\n",
        "df = pd.DataFrame(dict, index = data_index)\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uYmLQTgOPnX"
      },
      "source": [
        "## Manipulating DataFrames\n",
        "We can fetch values in a DataFrame by columns and index. Each column in a DataFrame is essentially a Pandas Series. We can fetch a column by square brackets: **df['column_name']**\n",
        "\n",
        "If a column name contains no spaces, then we can also use df.column_name to fetch a column:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pB2f7lBHW9_"
      },
      "source": [
        "df = aapl_table\n",
        "print(df.close.tail(5))\n",
        "print(df['volume'].tail(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0ugOel9O4-P"
      },
      "source": [
        "All the methods we applied to a Series index such as iloc[], loc[] and resampling methods, can also be applied to a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8dfjkedHW9_"
      },
      "source": [
        "aapl_2016 = df['2016']\n",
        "aapl_month = aapl_2016.resample('M').agg(lambda x: x[-1])\n",
        "print(aapl_month)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqrbrbFZPTJe"
      },
      "source": [
        "We may select certain columns of a DataFrame using their names:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7bQGeyCAHW9_"
      },
      "source": [
        "aapl_bar = aapl_month[['open', 'high', 'low', 'close']]\n",
        "print(aapl_bar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CQaZCAQP68O"
      },
      "source": [
        "We can even specify both rows and columns using loc[]. The row indices and column names are separated by a comma:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjWWiHVpHW-A"
      },
      "source": [
        "print(aapl_month.loc['2016-03':'2016-06', ['open', 'high', 'low', 'close']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xcn_pHNLQBEH"
      },
      "source": [
        "The subset methods in DataFrame is quite useful. By writing logical statements in square brackets, we can make customized subsets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxKg4dObHW-A"
      },
      "source": [
        "above = aapl_bar[aapl_bar.close > np.mean(aapl_bar.close)]\n",
        "print(above)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcm_UadkQLL5"
      },
      "source": [
        "## Data Validation\n",
        "As mentioned, all methods that apply to a Series can also be applied to a DataFrame. Here we add a new column to an existing DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZXFdOVFHW-A"
      },
      "source": [
        "aapl_bar['rate_return'] = aapl_bar.close.pct_change()\n",
        "print(aapl_bar)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_or6n5-LQUa-"
      },
      "source": [
        "Here the calculation introduced a NaN value. If the DataFrame is large, we would not be able to observe it. **isnull()** provides a convenient way to check abnormal values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5wgmhIPHW-B"
      },
      "source": [
        "missing = aapl_bar.isnull()\n",
        "print(missing)\n",
        "print('---------------------------------------------')\n",
        "print(missing.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6KFV4i0QfLW"
      },
      "source": [
        "The row labelled \"unique\" indicates the number of unique values in each column. Since the \"rate_return\" column has 2 unique values, it has at least one missing value.\n",
        "\n",
        "We can deduce the number of missing values by comparing \"count\" with \"freq\". There are 12 counts and 11 False values, so there is one True value which corresponds to the missing value.\n",
        "\n",
        "We can also find the rows with missing values easily:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eo0ZAhCsHW-B"
      },
      "source": [
        "print(missing[missing.rate_return == True])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgggpD8OQkZX"
      },
      "source": [
        "Usually when dealing with missing data, we either delete the whole row or fill it with some value. As we introduced in the Series chapter, the same method **dropna()** and **fillna()** can be applied to a DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8PaIokjHW-B"
      },
      "source": [
        "drop = aapl_bar.dropna()\n",
        "print(drop)\n",
        "print('\\n--------------------------------------------------\\n')\n",
        "fill = aapl_bar.fillna(0)\n",
        "print(fill)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tvoFlKWQxYG"
      },
      "source": [
        "## DataFrame Concat\n",
        "We have seen how to extract a Series from a dataFrame. Now we need to consider how to merge a Series or a DataFrame into another one.\n",
        "\n",
        "In Pandas, the function **concat()** allows us to merge multiple Series into a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQrmLIWKHW-C"
      },
      "source": [
        "s1 = pd.Series([143.5, 144.09, 142.73, 144.18, 143.77], name = 'AAPL')\n",
        "s2 = pd.Series([898.7, 911.71, 906.69, 918.59, 926.99], name = 'GOOG')\n",
        "data_frame = pd.concat([s1,s2], axis = 1)\n",
        "print(data_frame)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ojbNYJLR2vv"
      },
      "source": [
        "The \"axis = 1\" parameter will join two DataFrames by columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJsaLd-cRoIm"
      },
      "source": [
        "log_price = np.log(aapl_bar.Close)\n",
        "log_price.name = 'log_price'\n",
        "print(log_price)\n",
        "print('\\n---------------------- separate line--------------------\\n')\n",
        "concat = pd.concat([aapl_bar, log_price], axis = 1)\n",
        "print(concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIZz-FUyR_62"
      },
      "source": [
        "We can also join two DataFrames by rows. Consider these two DataFrames:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7uXZptLHW-C"
      },
      "source": [
        "df_volume = aapl_table.loc['2016-10':'2017-04', ['volume']].resample('M').agg(lambda x: x[-1])\n",
        "print(df_volume)\n",
        "print('\\n-------------------------------------------\\n')\n",
        "df_2017 = aapl_table.loc['2016-10':'2017-04', ['open', 'high', 'low', 'close']].resample('M').agg(lambda x: x[-1])\n",
        "print(df_2017)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZk_C9aSSLeP"
      },
      "source": [
        "Now we merge the DataFrames with our DataFrame 'aapl_bar'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFqmjokOHW-C"
      },
      "source": [
        "concat = pd.concat([aapl_bar, df_volume], axis = 1)\n",
        "print(concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yI3tgB4SR4O"
      },
      "source": [
        "By default the DataFrame are joined with all of the data. This default options results in zero information loss. We can also merge them by intersection, this is called 'inner join"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31QGLyijHW-C"
      },
      "source": [
        "concat = pd.concat([aapl_bar,df_volume],axis = 1, join = 'inner')\n",
        "print(concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oudcWMm5Sd0u"
      },
      "source": [
        "Only the intersection part was left if use 'inner join' method. Now let's try to append a DataFrame to another one:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgw0qaOsHW-D"
      },
      "source": [
        "append = aapl_bar.append(df_2017)\n",
        "print(append)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXT6cMquSq_P"
      },
      "source": [
        "'Append' is essentially to concat two DataFrames by axis = 0, thus here is an alternative way to append:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EuSaFO9HW-D"
      },
      "source": [
        "concat = pd.concat([aapl_bar, df_2017], axis = 0)\n",
        "print(concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YXL7V9ASst9"
      },
      "source": [
        "Please note that if the two DataFrame have some columns with the same column names, these columns are considered to be the same and will be merged. It's very important to have the right column names. If we change a column names here:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT1eoa8mHW-D"
      },
      "source": [
        "df_2017.columns = ['change', 'high', 'low', 'close']\n",
        "concat = pd.concat([aapl_bar, df_2017], axis = 0,sort=True)\n",
        "print(concat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shbpOFyyS6uV"
      },
      "source": [
        "Since the column name of 'Open' has been changed, the new DataFrame has an new column named 'Change'.\n",
        "\n",
        "# Summary\n",
        "\n",
        "Hereby we introduced the most import part of python: resampling and DataFrame manipulation. We only introduced the most commonly used method in Financial data analysis. There are also many methods used in data mining, which are also beneficial. You can always check the [Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html) official documentations for help."
      ]
    }
  ]
}